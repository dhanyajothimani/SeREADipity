{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, chi2, f_regression, SelectFromModel, VarianceThreshold, RFE\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "import operator\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# classifiers\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC,  LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# Model and Performance Metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A 23-year-old white female presents with comp...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female pr...</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 2</td>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climb...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 1</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , I have seen ABC ...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2-D M-Mode. Doppler.</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 1</td>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 2</td>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0   A 23-year-old white female presents with comp...   \n",
       "1           1           Consult for laparoscopic gastric bypass.   \n",
       "2           2           Consult for laparoscopic gastric bypass.   \n",
       "3           3                             2-D M-Mode. Doppler.     \n",
       "4           4                                 2-D Echocardiogram   \n",
       "\n",
       "             medical_specialty                                sample_name  \\\n",
       "0         Allergy / Immunology                         Allergic Rhinitis    \n",
       "1                   Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
       "2                   Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n",
       "3   Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n",
       "4   Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n",
       "\n",
       "                                       transcription  \\\n",
       "0  SUBJECTIVE:,  This 23-year-old white female pr...   \n",
       "1  PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
       "2  HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  allergy / immunology, allergic rhinitis, aller...  \n",
       "1  bariatrics, laparoscopic gastric bypass, weigh...  \n",
       "2  bariatrics, laparoscopic gastric bypass, heart...  \n",
       "3  cardiovascular / pulmonary, 2-d m-mode, dopple...  \n",
       "4  cardiovascular / pulmonary, 2-d, doppler, echo...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_sample = pd.read_csv('mtsamples.csv')\n",
    "mt_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4999, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4966, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mt_sample.shape)\n",
    "mt_subsample = mt_sample[['transcription', 'medical_specialty']]\n",
    "mt_subsample = mt_subsample.drop(mt_subsample[mt_subsample['transcription'].isna()].index)\n",
    "mt_subsample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Surgery                          1088\n",
       " Consult - History and Phy.        516\n",
       " Cardiovascular / Pulmonary        371\n",
       " Orthopedic                        355\n",
       " Radiology                         273\n",
       " General Medicine                  259\n",
       " Gastroenterology                  224\n",
       " Neurology                         223\n",
       " SOAP / Chart / Progress Notes     166\n",
       " Urology                           156\n",
       " Obstetrics / Gynecology           155\n",
       " Discharge Summary                 108\n",
       " ENT - Otolaryngology               96\n",
       " Neurosurgery                       94\n",
       " Hematology - Oncology              90\n",
       " Ophthalmology                      83\n",
       " Nephrology                         81\n",
       " Emergency Room Reports             75\n",
       " Pediatrics - Neonatal              70\n",
       " Pain Management                    61\n",
       " Psychiatry / Psychology            53\n",
       " Office Notes                       50\n",
       " Podiatry                           47\n",
       " Dermatology                        29\n",
       " Cosmetic / Plastic Surgery         27\n",
       " Dentistry                          27\n",
       " Letters                            23\n",
       " Physical Medicine - Rehab          21\n",
       " Sleep Medicine                     20\n",
       " Endocrinology                      19\n",
       " Bariatrics                         18\n",
       " IME-QME-Work Comp etc.             16\n",
       " Chiropractic                       14\n",
       " Diets and Nutritions               10\n",
       " Rheumatology                       10\n",
       " Speech - Language                   9\n",
       " Autopsy                             8\n",
       " Lab Medicine - Pathology            8\n",
       " Allergy / Immunology                7\n",
       " Hospice - Palliative Care           6\n",
       "Name: medical_specialty, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_subsample[\"medical_specialty\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Surgery                       1088\n",
       " Consult - History and Phy.     516\n",
       " Cardiovascular / Pulmonary     371\n",
       "Name: medical_specialty, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = mt_subsample['medical_specialty'].value_counts()\n",
    "mt_subsample_370 = mt_subsample[mt_subsample['medical_specialty'].isin(counts[counts > 370].index)]\n",
    "mt_subsample_370['labels'] = LabelEncoder().fit_transform(mt_subsample_370['medical_specialty'])\n",
    "mt_subsample_370['medical_specialty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370\n",
      "370\n",
      "370\n",
      "(1110, 3)\n"
     ]
    }
   ],
   "source": [
    "mt_subsample_370 = pd.DataFrame(mt_subsample_370)\n",
    "samp_cardio = mt_subsample_370[mt_subsample_370[\"labels\"]==0].sample(370)\n",
    "print(len(samp_cardio))\n",
    "samp_consult = mt_subsample_370[mt_subsample_370[\"labels\"]==1].sample(370)\n",
    "print(len(samp_consult))\n",
    "samp_surgery = mt_subsample_370[mt_subsample_370[\"labels\"]==2].sample(370)\n",
    "print(len(samp_surgery))\n",
    "mt_train_test=pd.concat([samp_cardio , samp_consult , samp_surgery])\n",
    "mt_train_test = mt_train_test.sample(frac=1)\n",
    "print(mt_train_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(narratives, stem=False,lem=True):\n",
    "    collection = []\n",
    "    tokenizer=RegexpTokenizer(r\"\\w+\")\n",
    "    for row in narratives:\n",
    "        tokens=tokenizer.tokenize(row)\n",
    "       \n",
    "        if lem==True:\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            tokens = [lemmatizer.lemmatize(t,pos=\"v\") for t in tokens]\n",
    "        elif stem==True:\n",
    "            stemmer = PorterStemmer()\n",
    "            tokens = [stemmer.stem(t) for t in tokens]\n",
    "        tokens = [word for word in tokens if word.isalpha()]#Just keep the words and removes numbers\n",
    "        tokens = [w.lower() for w in tokens]#words to lower case\n",
    "        tokens = [w for w in tokens if not w in stop_words]#Removing the stop words\n",
    "        collection.append(\" \".join(tokens))\n",
    "    return collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref: https://stackoverflow.com/questions/25462407/fast-information-gain-computation/38582697#38582697\n",
    "def information_gain(X, y):\n",
    "\n",
    "    def _calIg():\n",
    "        entropy_x_set = 0\n",
    "        entropy_x_not_set = 0\n",
    "        for c in classCnt:\n",
    "            probs = classCnt[c] / float(featureTot)\n",
    "            entropy_x_set = entropy_x_set - probs * np.log(probs)\n",
    "            probs = (classTotCnt[c] - classCnt[c]) / float(tot - featureTot)\n",
    "            entropy_x_not_set = entropy_x_not_set - probs * np.log(probs)\n",
    "        for c in classTotCnt:\n",
    "            if c not in classCnt:\n",
    "                probs = classTotCnt[c] / float(tot - featureTot)\n",
    "                entropy_x_not_set = entropy_x_not_set - probs * np.log(probs)\n",
    "        return entropy_before - ((featureTot / float(tot)) * entropy_x_set\n",
    "                             +  ((tot - featureTot) / float(tot)) * entropy_x_not_set)\n",
    "\n",
    "    tot = X.shape[0]\n",
    "    classTotCnt = {}\n",
    "    entropy_before = 0\n",
    "    for i in y:\n",
    "        if i not in classTotCnt:\n",
    "            classTotCnt[i] = 1\n",
    "        else:\n",
    "            classTotCnt[i] = classTotCnt[i] + 1\n",
    "    for c in classTotCnt:\n",
    "        probs = classTotCnt[c] / float(tot)\n",
    "        entropy_before = entropy_before - probs * np.log(probs)\n",
    "\n",
    "    nz = X.T.nonzero()\n",
    "    pre = 0\n",
    "    classCnt = {}\n",
    "    featureTot = 0\n",
    "    information_gain = []\n",
    "    for i in range(0, len(nz[0])):\n",
    "        if (i != 0 and nz[0][i] != pre):\n",
    "            for notappear in range(pre+1, nz[0][i]):\n",
    "                information_gain.append(0)\n",
    "            ig = _calIg()\n",
    "            information_gain.append(ig)\n",
    "            pre = nz[0][i]\n",
    "            classCnt = {}\n",
    "            featureTot = 0\n",
    "        featureTot = featureTot + 1\n",
    "        yclass = y[nz[1][i]]\n",
    "        if yclass not in classCnt:\n",
    "            classCnt[yclass] = 1\n",
    "        else:\n",
    "            classCnt[yclass] = classCnt[yclass] + 1\n",
    "    ig = _calIg()\n",
    "    information_gain.append(ig)\n",
    "\n",
    "    return np.asarray(information_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1110, 3)\n",
      "(1110, 3)\n"
     ]
    }
   ],
   "source": [
    "mt_train_test_preprocessed = mt_train_test\n",
    "print(mt_train_test.shape)\n",
    "mt_train_test_preprocessed[\"transcription\"] =  preprocess(mt_train_test_preprocessed[\"transcription\"])\n",
    "mt_train_test_preprocessed = mt_train_test_preprocessed.drop(mt_train_test_preprocessed[mt_train_test_preprocessed['transcription'].isna()].index)\n",
    "print(mt_train_test_preprocessed.shape)\n",
    "mt_train_test_preprocessed.head()\n",
    "mt_train_test_preprocessed.to_csv(\"preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_splits 5\n",
      "Train:  (888,) (888,)\n",
      "Test:  (222,) (222,)\n",
      "(888, 1)\n",
      "X_train_vec (888, 12170)\n",
      "X_test_vec (222, 12170)\n"
     ]
    }
   ],
   "source": [
    "#Splitting Training and Test Dataset\n",
    "X = mt_train_test_preprocessed[\"transcription\"]\n",
    "X=X.reset_index(drop=True)  #Ref: https://stackoverflow.com/questions/43307156/sklearns-kfold-generates-nan-values\n",
    "y = mt_train_test_preprocessed[\"medical_specialty\"]\n",
    "y=y.reset_index(drop=True)\n",
    "skf = StratifiedKFold(n_splits=5,random_state = 7, shuffle=True)\n",
    "print(\"n_splits\",skf.get_n_splits(X, y))\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "#     print(X_train, X_test)\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "print(\"Train: \", X_train.shape,y_train.shape)\n",
    "print(\"Test: \", y_test.shape,y_test.shape)\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train).reset_index(drop=True)\n",
    "#X_train = X_train.drop(X_train[X_train['transcription'].isna()].index)\n",
    "print(X_train.shape)\n",
    "# print(X_train.head())\n",
    "X_test = pd.DataFrame(X_test).reset_index(drop=True)\n",
    "y_train = pd.DataFrame(y_train).reset_index(drop=True)\n",
    "# print(y_train.shape)\n",
    "y_test = pd.DataFrame(y_test).reset_index(drop=True)\n",
    "vect = TfidfVectorizer()\n",
    "X_train_vec = vect.fit_transform(X_train[\"transcription\"])\n",
    "X_test_vec = vect.transform(X_test[\"transcription\"])\n",
    "print(\"X_train_vec\",X_train_vec.shape)\n",
    "print(\"X_test_vec\",X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for RF is 0.709\n"
     ]
    }
   ],
   "source": [
    "#No Feature Selection\n",
    "\n",
    "models_dic={\"RF\": RandomForestClassifier(random_state=1)}\n",
    "for name, model in models_dic.items():\n",
    "    clf = Pipeline([('vect', TfidfVectorizer()), ('model', model)])\n",
    "    scores_tfidf = np.mean(cross_val_score(clf, mt_train_test_preprocessed[\"transcription\"], \n",
    "                                           mt_train_test_preprocessed[\"medical_specialty\"], cv=5))\n",
    "    print(\"Accuracy for {} is {}\".format(name,round(scores_tfidf,3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features before fs:  (888, 12170)\n",
      "reduced features for ELR:(888, 200) \n",
      "features before fs:  (888, 12170)\n",
      "reduced features for ExT:(888, 200) \n",
      "features before fs:  (888, 12170)\n",
      "reduced features for Chi2:(888, 200) \n",
      "features before fs:  (888, 12170)\n",
      "features before fs:  (888, 12170)\n",
      "features before fs:  (888, 12170)\n",
      "reduced features for L1:(888, 297) \n",
      "features before fs:  (888, 12170)\n",
      "reduced features for V:(888, 1204) \n"
     ]
    }
   ],
   "source": [
    "words_num =200\n",
    "FS_methods = {\"ELR\" : SelectFromModel(LogisticRegression(), max_features = words_num), \n",
    "              \"ExT\": SelectFromModel(ExtraTreesClassifier(n_estimators=50), max_features = words_num),\n",
    "              \"Chi2\" : SelectKBest(chi2, k=words_num),\n",
    "              #\"RFE\": RFE(estimator=SVC(kernel=\"linear\", C=1), n_features_to_select=words_num, step=1),\n",
    "              \"MuI\": 0 ,\n",
    "              \"IG\" : 0 ,\n",
    "              \"L1\":  SelectFromModel(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "              \"V\": VarianceThreshold(0.0001999),\n",
    "             } \n",
    "df_words = pd.DataFrame(columns = list(FS_methods.keys()))\n",
    "\n",
    "for name, model in FS_methods.items():\n",
    "    count_vect = CountVectorizer(input=\"transcription\", analyzer=\"word\")\n",
    "    X_train_counts = count_vect.fit_transform(X_train[\"transcription\"])\n",
    "    #     print(\"features before fs:\", X_train_counts.shape)\n",
    "    tf_transformer = TfidfTransformer(use_idf=True)\n",
    "    traindata = tf_transformer.fit_transform(X_train_counts)\n",
    "    print(\"features before fs: \", traindata.shape) #report size of the training data\n",
    "    if name == \"MuI\":\n",
    "        res = dict(zip(count_vect.get_feature_names(),\n",
    "                           mutual_info_classif(traindata, y_train[\"medical_specialty\"], discrete_features=True)\n",
    "                           ))\n",
    "            #print(res)\n",
    "        MI_ordered = sorted(res, key=res.get)\n",
    "        MI_FS = MI_ordered [:words_num]\n",
    "        df_words[name] =  MI_FS\n",
    "    elif name == \"IG\":\n",
    "        IG_dict = dict(zip(count_vect.get_feature_names(),\n",
    "                       information_gain(traindata, y_train[\"medical_specialty\"])\n",
    "                       ))\n",
    "        IG_ordered = sorted(IG_dict, key=IG_dict.get)\n",
    "        IG_FS = IG_ordered [:words_num]\n",
    "        df_words[name] = IG_FS\n",
    "\n",
    "    else:   \n",
    "        X_transform = model.fit_transform(traindata, y_train[\"medical_specialty\"])\n",
    "        print(\"reduced features for {}:{} \".format(name, X_transform.shape))\n",
    "            #get the names of all features\n",
    "        words = np.array(count_vect.get_feature_names())\n",
    "          #         print(words[:10])\n",
    "            #get the names of the important features using the boolean index from model \n",
    "        if X_transform.shape[1] < words_num:\n",
    "            red_length = X_transform.shape[1]\n",
    "            print(red_length)\n",
    "            df_words[name] = words[model.get_support()][:red_length] \n",
    "        else:\n",
    "            df_words[name] = words[model.get_support()][:words_num]\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ELR</th>\n",
       "      <th>ExT</th>\n",
       "      <th>Chi2</th>\n",
       "      <th>MuI</th>\n",
       "      <th>IG</th>\n",
       "      <th>L1</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ago</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>advance</td>\n",
       "      <td>abciximab</td>\n",
       "      <td>abandon</td>\n",
       "      <td>able</td>\n",
       "      <td>abdomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>age</td>\n",
       "      <td>accelerate</td>\n",
       "      <td>acetic</td>\n",
       "      <td>actually</td>\n",
       "      <td>abdominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alert</td>\n",
       "      <td>alert</td>\n",
       "      <td>ago</td>\n",
       "      <td>acidophilus</td>\n",
       "      <td>adequacy</td>\n",
       "      <td>ago</td>\n",
       "      <td>able</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allergies</td>\n",
       "      <td>allergies</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>acidotic</td>\n",
       "      <td>adhesives</td>\n",
       "      <td>albuterol</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>also</td>\n",
       "      <td>anesthesia</td>\n",
       "      <td>alert</td>\n",
       "      <td>acs</td>\n",
       "      <td>albeit</td>\n",
       "      <td>alert</td>\n",
       "      <td>abnormalities</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ELR         ExT     Chi2          MuI         IG         L1  \\\n",
       "0        ago     abdomen  advance    abciximab    abandon       able   \n",
       "1    alcohol     alcohol      age   accelerate     acetic   actually   \n",
       "2      alert       alert      ago  acidophilus   adequacy        ago   \n",
       "3  allergies   allergies  alcohol     acidotic  adhesives  albuterol   \n",
       "4       also  anesthesia    alert          acs     albeit      alert   \n",
       "\n",
       "               V  \n",
       "0        abdomen  \n",
       "1      abdominal  \n",
       "2           able  \n",
       "3       abnormal  \n",
       "4  abnormalities  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words.to_csv(\"word.csv\")\n",
    "df_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1217\n",
      "Accuracy for RF_ELR_0.1 is 0.723\n",
      "2434\n",
      "Accuracy for RF_ELR_0.2 is 0.723\n",
      "3651\n",
      "Accuracy for RF_ELR_0.3 is 0.723\n",
      "4868\n",
      "Accuracy for RF_ELR_0.4 is 0.723\n",
      "6085\n",
      "Accuracy for RF_ELR_0.5 is 0.723\n",
      "1217\n",
      "Accuracy for RF_ExT_0.1 is 0.716\n",
      "2434\n",
      "Accuracy for RF_ExT_0.2 is 0.711\n",
      "3651\n",
      "Accuracy for RF_ExT_0.3 is 0.724\n",
      "4868\n",
      "Accuracy for RF_ExT_0.4 is 0.722\n",
      "6085\n",
      "Accuracy for RF_ExT_0.5 is 0.712\n",
      "1217\n",
      "Accuracy for RF_V_0.1 is 0.709\n",
      "2434\n",
      "Accuracy for RF_V_0.2 is 0.709\n",
      "3651\n",
      "Accuracy for RF_V_0.3 is 0.709\n",
      "4868\n",
      "Accuracy for RF_V_0.4 is 0.709\n",
      "6085\n",
      "Accuracy for RF_V_0.5 is 0.709\n",
      "1217\n",
      "Accuracy for RF_Chi2_0.1 is 0.717\n",
      "2434\n",
      "Accuracy for RF_Chi2_0.2 is 0.717\n",
      "3651\n",
      "Accuracy for RF_Chi2_0.3 is 0.717\n",
      "4868\n",
      "Accuracy for RF_Chi2_0.4 is 0.717\n",
      "6085\n",
      "Accuracy for RF_Chi2_0.5 is 0.717\n",
      "1217\n",
      "Accuracy for RF_L1_0.1 is 0.733\n",
      "2434\n",
      "Accuracy for RF_L1_0.2 is 0.737\n",
      "3651\n",
      "Accuracy for RF_L1_0.3 is 0.734\n",
      "4868\n",
      "Accuracy for RF_L1_0.4 is 0.737\n",
      "6085\n",
      "Accuracy for RF_L1_0.5 is 0.73\n"
     ]
    }
   ],
   "source": [
    "words_count = round(0.10 * X_train_vec.shape[1])\n",
    "FS_methods = {\"ELR\" : SelectFromModel(LogisticRegression(), max_features = words_count), \n",
    "              \"ExT\": SelectFromModel(ExtraTreesClassifier(n_estimators=50), max_features = words_count),\n",
    "              \"V\": VarianceThreshold(0.0001999),\n",
    "              \"Chi2\" : SelectKBest(chi2, k=words_count),\n",
    "              \"L1\":  SelectFromModel(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "#               \"RFE\": RFE(estimator=SVC(kernel=\"linear\", C=1), n_features_to_select=words_count, step=1),\n",
    "#               \"MuI\": 0 ,\n",
    "#               \"IG\" : 0 ,\n",
    "             } \n",
    "\n",
    "\n",
    "models_dic={\"RF\": RandomForestClassifier(random_state=1)}\n",
    "res_accuracy = pd.DataFrame()\n",
    "for name, model in models_dic.items():\n",
    "    for fs_name, fs_model in FS_methods.items():\n",
    "        for j in [0.10, 0.20, 0.30, 0.40, 0.50]:\n",
    "            words_count = round(j * X_train_vec.shape[1])\n",
    "            if fs_name == \"MuI\":\n",
    "                res = dict(zip(count_vect.get_feature_names(),\n",
    "                                   mutual_info_classif(traindata, y_train[\"medical_specialty\"], discrete_features=True)\n",
    "                                   ))\n",
    "                    #print(res)\n",
    "                MI_ordered = sorted(res, key=res.get)\n",
    "                MI_FS = MI_ordered[:words_count]\n",
    "                clf = Pipeline([('vect', TfidfVectorizer()), ('feature_selection', fs_model), \n",
    "                            ('model', model)])\n",
    "                scores_tfidf = np.mean(cross_val_score(clf, mt_train_test_preprocessed[\"transcription\"], \n",
    "                                                   mt_train_test_preprocessed[\"medical_specialty\"], cv=5))\n",
    "                print(\"Accuracy for {}_{} is {}\".format(name,fs_name,round(scores_tfidf,3)))    \n",
    "            elif fs_name == \"IG\": \n",
    "                IG_dict = dict(zip(count_vect.get_feature_names(),\n",
    "                               information_gain(traindata, y_train[\"medical_specialty\"])\n",
    "                               ))\n",
    "                IG_ordered = sorted(IG_dict, key=IG_dict.get)\n",
    "                IG_FS = IG_ordered [:words_count]\n",
    "                clf = Pipeline([('vect', TfidfVectorizer()), ('feature_selection', fs_model), \n",
    "                            ('model', model)])\n",
    "                scores_tfidf = np.mean(cross_val_score(clf, mt_train_test_preprocessed[\"transcription\"], \n",
    "                                                   mt_train_test_preprocessed[\"medical_specialty\"], cv=5))\n",
    "                print(\"Accuracy for {}_{} is {}\".format(name,fs_name,round(scores_tfidf,3)))\n",
    "            else: \n",
    "                #print(words_count)\n",
    "                clf = Pipeline([('vect', TfidfVectorizer()), ('feature_selection', fs_model), \n",
    "                            ('model', model)])\n",
    "                scores_tfidf = np.mean(cross_val_score(clf, mt_train_test_preprocessed[\"transcription\"], \n",
    "                                                   mt_train_test_preprocessed[\"medical_specialty\"], cv=5))\n",
    "                print(\"Accuracy for {}_{}_{} is {}\".format(name,fs_name,j, round(scores_tfidf,3)))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2434\n",
      "Accuracy for RF_ELR_0.2 is 0.723\n",
      "2434\n",
      "Accuracy for RF_ExT_0.2 is 0.713\n",
      "2434\n",
      "Accuracy for RF_V_0.2 is 0.709\n",
      "2434\n",
      "Accuracy for RF_Chi2_0.2 is 0.717\n",
      "2434\n",
      "Accuracy for RF_L1_0.2 is 0.734\n",
      "2434\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-b1d0ca285f33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m                             ('model', model)])\n\u001b[0;32m     45\u001b[0m                 scores_tfidf = np.mean(cross_val_score(clf, mt_train_test_preprocessed[\"transcription\"], \n\u001b[1;32m---> 46\u001b[1;33m                                                    mt_train_test_preprocessed[\"medical_specialty\"], cv=5))\n\u001b[0m\u001b[0;32m     47\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy for {}_{}_{} is {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfs_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_tfidf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \"\"\"\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    228\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[0;32m    229\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                     **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    231\u001b[0m                 \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[1;31m# Get coefs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 random_seed)\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\svm\\libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm_sparse.libsvm_sparse_train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;34m\"\"\"base matrix class for compressed row and column oriented matrices\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "words_count = round(0.10 * X_train_vec.shape[1])\n",
    "FS_methods = {\"ELR\" : SelectFromModel(LogisticRegression(), max_features = words_count), \n",
    "              \"ExT\": SelectFromModel(ExtraTreesClassifier(n_estimators=50), max_features = words_count),\n",
    "              \"V\": VarianceThreshold(0.0001999),\n",
    "              \"Chi2\" : SelectKBest(chi2, k=words_count),\n",
    "              \"L1\":  SelectFromModel(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "              \"RFE\": RFE(estimator=SVC(kernel=\"linear\", C=1), n_features_to_select=words_count, step=1),\n",
    "#               \"MuI\": 0 ,\n",
    "#               \"IG\" : 0 ,\n",
    "             } \n",
    "\n",
    "\n",
    "models_dic={\"RF\": RandomForestClassifier(random_state=1)}\n",
    "for name, model in models_dic.items():\n",
    "    for fs_name, fs_model in FS_methods.items():\n",
    "        for j in [ 0.20]:\n",
    "            words_count = round(j * X_train_vec.shape[1])\n",
    "            if fs_name == \"MuI\":\n",
    "                res = dict(zip(count_vect.get_feature_names(),\n",
    "                                   mutual_info_classif(traindata, y_train[\"medical_specialty\"], discrete_features=True)\n",
    "                                   ))\n",
    "                    #print(res)\n",
    "                MI_ordered = sorted(res, key=res.get)\n",
    "                MI_FS = MI_ordered[:words_count]\n",
    "                clf = Pipeline([('vect', TfidfVectorizer()), ('feature_selection', fs_model), \n",
    "                            ('model', model)])\n",
    "                scores_tfidf = np.mean(cross_val_score(clf, mt_train_test_preprocessed[\"transcription\"], \n",
    "                                                   mt_train_test_preprocessed[\"medical_specialty\"], cv=5))\n",
    "                print(\"Accuracy for {}_{} is {}\".format(name,fs_name,round(scores_tfidf,3)))    \n",
    "            elif fs_name == \"IG\": \n",
    "                IG_dict = dict(zip(count_vect.get_feature_names(),\n",
    "                               information_gain(traindata, y_train[\"medical_specialty\"])\n",
    "                               ))\n",
    "                IG_ordered = sorted(IG_dict, key=IG_dict.get)\n",
    "                IG_FS = IG_ordered [:words_count]\n",
    "                clf = Pipeline([('vect', TfidfVectorizer()), ('feature_selection', fs_model), \n",
    "                            ('model', model)])\n",
    "                scores_tfidf = np.mean(cross_val_score(clf, mt_train_test_preprocessed[\"transcription\"], \n",
    "                                                   mt_train_test_preprocessed[\"medical_specialty\"], cv=5))\n",
    "                print(\"Accuracy for {}_{} is {}\".format(name,fs_name,round(scores_tfidf,3)))\n",
    "            else: \n",
    "                print(words_count)\n",
    "                clf = Pipeline([('vect', TfidfVectorizer()), ('feature_selection', fs_model), \n",
    "                            ('model', model)])\n",
    "                scores_tfidf = np.mean(cross_val_score(clf, mt_train_test_preprocessed[\"transcription\"], \n",
    "                                                   mt_train_test_preprocessed[\"medical_specialty\"], cv=5))\n",
    "                print(\"Accuracy for {}_{}_{} is {}\".format(name,fs_name,j, round(scores_tfidf,3)))    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
